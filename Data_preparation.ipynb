{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##   MLP: https://www.kaggle.com/rgaddati/santander-customer-satisfaction/santander1\n",
    "\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "#from __future__ import division\n",
    "\n",
    "import multiprocessing\n",
    "N_PROCESSES = 8\n",
    "\n",
    "%matplotlib inline  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_validation import StratifiedKFold \n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from scipy.stats import describe\n",
    "from sklearn.preprocessing import StandardScaler, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75818, 370)\n",
      "(76020, 371)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"Data/train.csv\")\n",
    "df_test = pd.read_csv(\"Data/test.csv\")\n",
    "\n",
    "print(df_test.shape)\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## ## Join train and test data ## ##\n",
    "\n",
    "# zero_col = np.zeros(df_test.shape[0])\n",
    "# zero_col = pd.DataFrame(zero_col,columns=['id'])\n",
    "# zero_col.iloc[:] = -1\n",
    "# print(zero_col.shape)\n",
    "\n",
    "# df_test[\"TARGET\"] = zero_col\n",
    "# print (df_test.shape)\n",
    "\n",
    "# df_train = pd.concat ([df_train,df_test])\n",
    "# df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75818, 336)\n",
      "(76020, 337)\n"
     ]
    }
   ],
   "source": [
    "# remove constant columns\n",
    "remove = []\n",
    "for col in df_train.columns:\n",
    "    if df_train[col].std() == 0:\n",
    "        remove.append(col)\n",
    "\n",
    "df_train.drop(remove, axis=1, inplace=True)\n",
    "df_test.drop(remove, axis=1, inplace=True)\n",
    "\n",
    "print(df_test.shape)\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39205.170000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49278.030000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67333.770000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>195</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64007.970000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>117310.979016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 337 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0   1     2     23                   0                        0   \n",
       "1   3     2     34                   0                        0   \n",
       "2   4     2     23                   0                        0   \n",
       "3   8     2     37                   0                      195   \n",
       "4  10     2     39                   0                        0   \n",
       "\n",
       "   imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "0                        0                        0                        0   \n",
       "1                        0                        0                        0   \n",
       "2                        0                        0                        0   \n",
       "3                      195                        0                        0   \n",
       "4                        0                        0                        0   \n",
       "\n",
       "   imp_op_var40_efect_ult1  imp_op_var40_efect_ult3   ...    \\\n",
       "0                        0                        0   ...     \n",
       "1                        0                        0   ...     \n",
       "2                        0                        0   ...     \n",
       "3                        0                        0   ...     \n",
       "4                        0                        0   ...     \n",
       "\n",
       "   saldo_medio_var33_hace2  saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "0                        0                        0                       0   \n",
       "1                        0                        0                       0   \n",
       "2                        0                        0                       0   \n",
       "3                        0                        0                       0   \n",
       "4                        0                        0                       0   \n",
       "\n",
       "   saldo_medio_var33_ult3  saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "0                       0                        0                        0   \n",
       "1                       0                        0                        0   \n",
       "2                       0                        0                        0   \n",
       "3                       0                        0                        0   \n",
       "4                       0                        0                        0   \n",
       "\n",
       "   saldo_medio_var44_ult1  saldo_medio_var44_ult3          var38  TARGET  \n",
       "0                       0                       0   39205.170000       0  \n",
       "1                       0                       0   49278.030000       0  \n",
       "2                       0                       0   67333.770000       0  \n",
       "3                       0                       0   64007.970000       0  \n",
       "4                       0                       0  117310.979016       0  \n",
       "\n",
       "[5 rows x 337 columns]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75818, 307)\n",
      "(76020, 308)\n"
     ]
    }
   ],
   "source": [
    "# remove duplicated columns\n",
    "remove = []\n",
    "c = df_train.columns\n",
    "for i in range(len(c)-1):\n",
    "    v = df_train[c[i]].values\n",
    "    for j in range(i+1,len(c)):\n",
    "        if np.array_equal(v,df_train[c[j]].values):\n",
    "            remove.append(c[j])\n",
    "\n",
    "df_train.drop(remove, axis=1, inplace=True)\n",
    "df_test.drop(remove, axis=1, inplace=True)\n",
    "\n",
    "y_train = df_train['TARGET'].values\n",
    "X_train = df_train.drop(['ID','TARGET'], axis=1).values\n",
    "\n",
    "id_test = df_test['ID']\n",
    "X_test = df_test.drop(['ID'], axis=1).values\n",
    "\n",
    "feature_names = df_train.columns.values \n",
    "feature_names = feature_names[1:feature_names.shape[0]-1]  ## removing ID and Target\n",
    "\n",
    "print(df_test.shape)\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76020, 252)\n",
      "(75818, 252)\n"
     ]
    }
   ],
   "source": [
    "## ## removing features with high presence of nulls\n",
    "\n",
    "col_remove = X_train.shape[0]-sum(X_train == 0)<10\n",
    "X_train = X_train[:,~col_remove]\n",
    "X_test = X_test[:,~col_remove]\n",
    "feature_names = feature_names[~col_remove]\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76020\n",
      "(151838, 252)\n"
     ]
    }
   ],
   "source": [
    "train_size = X_train.shape[0]\n",
    "print train_size\n",
    "\n",
    "Data_all = np.concatenate([X_train,X_test],axis = 0)\n",
    "Data_all.shape\n",
    "print Data_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236\n"
     ]
    }
   ],
   "source": [
    "##  I would suggest not to change -999999 into anything other  \n",
    "## \n",
    "num_vals = (Data_all[:,0]==-999999)\n",
    "print (sum(num_vals))\n",
    "Data_all[num_vals,0] = -5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(151838, 252)\n",
      "(151838, 268)\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "##  Converting cities to numbers\n",
    "##\n",
    "\n",
    "def get_cities_val_count (args):\n",
    "    zero_col = args[0]\n",
    "    cities_val = args[1]\n",
    "    if sum(zero_col[:train_size] == cities_val)>60:\n",
    "        new_col = np.zeros(zero_col.shape[0])\n",
    "        new_col[(zero_col[:] == cities_val)] = 1\n",
    "        return np.array(new_col)\n",
    "\n",
    "\n",
    "zero_col = Data_all[:,0]\n",
    "zero_col.shape\n",
    "\n",
    "cities_vals = np.unique(Data_all[:train_size,0])\n",
    "\n",
    "pool = multiprocessing.Pool(N_PROCESSES)\n",
    "tt = pool.map(get_cities_val_count, zip([zero_col]*cities_vals.shape[0],cities_vals) )\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "tt = np.array(tt)\n",
    "none_filter = map (lambda x: x is None, tt)\n",
    "tt = tt[~np.array(none_filter)]\n",
    "tt = np.vstack(tt).T\n",
    "\n",
    "print Data_all.shape\n",
    "Data_all = np.column_stack([Data_all, tt])  \n",
    "\n",
    "print Data_all.shape\n",
    "print \"finished\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               0      1\n",
      "0  -1.000000e+00   1675\n",
      "1  -9.038462e-01      1\n",
      "2  -8.333333e-01      1\n",
      "3  -8.000000e-01      1\n",
      "4  -7.602877e-01      1\n",
      "5  -6.666667e-01      1\n",
      "6  -5.000000e-01      2\n",
      "7  -4.995000e-01      1\n",
      "8  -3.494898e-01      1\n",
      "9  -3.333333e-01      2\n",
      "10 -2.910826e-01      1\n",
      "11 -1.973684e-01      1\n",
      "12 -1.000000e-01      1\n",
      "13 -9.090909e-02      1\n",
      "14  0.000000e+00  73948\n",
      "15  1.538462e-01      1\n",
      "16  1.605039e-01      1\n",
      "17  4.000000e-01      1\n",
      "18  1.000000e+00      1\n",
      "19  1.181818e+00      1\n",
      "20  1.222222e+00      1\n",
      "21  1.445714e+00      1\n",
      "22  1.777778e+00      1\n",
      "23  2.333092e+00      1\n",
      "24  4.000000e+00      2\n",
      "25  5.500000e+00      1\n",
      "26  1.000000e+10    370\n"
     ]
    }
   ],
   "source": [
    "## Get pandas dataframe with count for each val \n",
    "def get_vals(a):\n",
    "    tt = map (lambda x: [x, sum(a==x)], np.unique(a))\n",
    "    return pd.DataFrame(tt)  \n",
    "\n",
    "\n",
    "aa = get_vals(X_train[:,138])\n",
    "print aa.iloc[:,:]\n",
    "pd.set_option(\"display.max_rows\",255)\n",
    "pd.set_option(\"display.max_colwidth\",250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count columns:  124\n",
      "(151838, 268)\n",
      "finished\n",
      "(151838, 270)\n"
     ]
    }
   ],
   "source": [
    "##  Counting number of zeros in columns\n",
    "##\n",
    "\n",
    "\n",
    "def count_values(a,val = 0):\n",
    "    return sum(a==val)\n",
    "\n",
    "\n",
    "# first select columns which are biased to zeroes:\n",
    "pool = multiprocessing.Pool(N_PROCESSES)\n",
    "tt = pool.map(count_values, map(lambda x: Data_all[:train_size,x],range(Data_all.shape[1])) )\n",
    "pool.close()\n",
    "pool.join()\n",
    "tt = np.array(tt)\n",
    "\n",
    "##  Count how many zeros are in this columns\n",
    "sel_cols = (tt > Data_all[:train_size,:].shape[0]*0.990)\n",
    "print \"count columns: \", sum(sel_cols)\n",
    "\n",
    "\n",
    "print (Data_all.shape)\n",
    "\n",
    "pool = multiprocessing.Pool(N_PROCESSES)\n",
    "tt = pool.map(count_values, map(lambda x: Data_all[x,sel_cols],range(Data_all.shape[0])) )\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "Data_all = np.column_stack((Data_all, tt)) \n",
    "\n",
    "## count zeros in all columns\n",
    "pool = multiprocessing.Pool(N_PROCESSES)\n",
    "tt = pool.map(count_values, map(lambda x: Data_all[x,:],range(Data_all.shape[0])) )\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "Data_all = np.column_stack((Data_all, tt)) \n",
    "\n",
    "\n",
    "print (\"finished\")\n",
    "\n",
    "\n",
    "print (Data_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0 370  39   1  70  38  20\n",
      "   5  42 370  39   1  70  42   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "def count_values(a,val = 9999999999):\n",
    "    return sum(a==val)\n",
    "\n",
    "\n",
    "# first select columns which are biased to zeroes:\n",
    "pool = multiprocessing.Pool(N_PROCESSES)\n",
    "tt = pool.map(count_values, map(lambda x: Data_all[:train_size,x],range(Data_all.shape[1])) )\n",
    "pool.close()\n",
    "pool.join()\n",
    "tt = np.array(tt)\n",
    "\n",
    "print tt\n",
    "print sum(tt>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['delta_imp_aport_var13_1y3', 'delta_imp_aport_var17_1y3',\n",
       "       'delta_imp_aport_var33_1y3', 'delta_imp_compra_var44_1y3',\n",
       "       'delta_imp_reemb_var13_1y3', 'delta_imp_reemb_var17_1y3',\n",
       "       'delta_imp_trasp_var33_in_1y3', 'delta_imp_venta_var44_1y3',\n",
       "       'delta_num_aport_var13_1y3', 'delta_num_aport_var17_1y3',\n",
       "       'delta_num_aport_var33_1y3', 'delta_num_compra_var44_1y3',\n",
       "       'delta_num_venta_var44_1y3'], dtype=object)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names[tt>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## replace missing values in columns with value that has the highest count\n",
    "## get value with highest appearance rate \n",
    "\n",
    "\n",
    "\n",
    "def sort_by_unique_get_most_occur(arr_vals):\n",
    "    t = dict()\n",
    "    for val in np.unique(arr_vals): \n",
    "        t[val] = sum(arr_vals == val) \n",
    "\n",
    "    val0  = sorted (t, key = t.get, reverse = True)[0]\n",
    "    return val0\n",
    "\n",
    "\n",
    "for j in filter_cols_number:\n",
    "\n",
    "    new_col = np.zeros(X_train.shape[0]) \n",
    "    new_col [X_train[:,j] == 9999999999.0] = 1\n",
    "    X_train = np.column_stack((X_train, new_col))\n",
    "    new_val = sort_by_unique_get_most_occur(X_train[X_train[:,j] != 9999999999.0,j])\n",
    "    X_train[X_train[:,j] == 9999999999.0,j] = new_val\n",
    "\n",
    "    new_col = np.zeros(X_test.shape[0])\n",
    "    new_col [X_test[:,j] == 9999999999.0] = 1\n",
    "    X_test = np.column_stack((X_test, new_col))     \n",
    "    new_val = sort_by_unique_get_most_occur(X_test[X_test[:,j] != 9999999999.0,j])\n",
    "    X_test[X_test[:,j] == 9999999999.0,j] = new_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## unique values in columns\n",
    "\n",
    "pd.set_option(\"display.max_rows\",255)\n",
    "pd.set_option(\"display.max_colwidth\",250)\n",
    "\n",
    "\n",
    "tt = map(lambda x: np.unique(X_train[:,x]), range(X_train.shape[1]))\n",
    "pd.DataFrame({'data': tt,'id': range(X_train.shape[1])},columns=['id','data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (np.unique(X_train[:,150]))\n",
    "print (np.unique(X_test[:,150]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "st_scale = StandardScaler(True, True, True)\n",
    "X_train = st_scale.fit_transform(X_train)\n",
    "X_test = st_scale.transform (X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sum(X_train[:,46] == -14.853708394243661)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (np.unique(X_train[:,150]))\n",
    "print (np.unique(X_test[:,150]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plt.plot(X_test.mean(axis=0), color =\"b\")\n",
    "plt.plot(X_train.mean(axis=0), color =\"r\")\n",
    "plt.show()\n",
    "#X_test.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.plot(X_test.mean(axis=0), color =\"b\")\n",
    "plt.plot(X_train.mean(axis=0), color =\"r\")\n",
    "plt.show()\n",
    "#X_test.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Feature selection\n",
    "\n",
    "clf = ExtraTreesClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "feature_selected = clf.feature_importances_\n",
    "\n",
    "print (\"ExtraTrees done\")\n",
    "\n",
    "feature_selected = np.argsort(-feature_selected)\n",
    "print (feature_selected[0:30])\n",
    "\n",
    "##   [305   1 268 270 266 264 263 221 265 267 223 150 143 269 219 218 128 224\n",
    "##    152 220  22 233 222   2  11 189  71  13  14   4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  https://www.kaggle.com/c/homesite-quote-conversion/forums/t/18837/what-is-your-best-single-model-score-and-how-did-you-achieve-it\n",
    "#\n",
    "#  Adding log features\n",
    "\n",
    "feat = feature_selected[0:100]\n",
    "\n",
    "c = X_train.shape[1]\n",
    "\n",
    "k = 0\n",
    "\n",
    "for i in feat:\n",
    "    k = k+1\n",
    "    if sum(X_train[:,i]<0)==0:\n",
    "        new_col = np.log(X_train[:,i]+1)\n",
    "        X_train = np.column_stack((X_train, new_col))\n",
    "\n",
    "        new_col = np.sqrt(X_train[:,i])\n",
    "        X_train = np.column_stack((X_train, new_col))\n",
    "\n",
    "        new_col = 1/(0.001 + X_train[:,i])\n",
    "        X_train = np.column_stack((X_train, new_col))        \n",
    "        \n",
    "        \n",
    "        new_col = np.log(X_test[:,i]+1)\n",
    "        X_test = np.column_stack((X_test, new_col))\n",
    "\n",
    "        new_col = np.sqrt(X_test[:,i])\n",
    "        X_test = np.column_stack((X_test, new_col))\n",
    "\n",
    "        new_col = 1/(0.001 + X_test[:,i])\n",
    "        X_test = np.column_stack((X_test, new_col))      \n",
    "        \n",
    "     \n",
    "    \n",
    "print(X_test.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_train.tofile(\"Data/proc_train.csv\", sep=\",\",format=\"%.2f\")\n",
    "#X_test.tofile(\"Data/proc_test.csv\", sep=\",\",format=\"%.2f\")\n",
    "\n",
    "np.savetxt(\"Data/proc_train.csv\", X_train, delimiter=\",\",  fmt='%.3e')\n",
    "np.savetxt(\"Data/proc_test.csv\", X_test, delimiter=\",\",  fmt='%.3e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
