{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##   MLP: https://www.kaggle.com/rgaddati/santander-customer-satisfaction/santander1\n",
    "\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "#from __future__ import division\n",
    "\n",
    "%matplotlib inline  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_validation import StratifiedKFold \n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from scipy.stats import describe\n",
    "from sklearn.preprocessing import StandardScaler, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75818, 370)\n",
      "(76020, 371)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"Data/train.csv\")\n",
    "df_test = pd.read_csv(\"Data/test.csv\")\n",
    "\n",
    "print(df_test.shape)\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## ## Join train and test data ## ##\n",
    "\n",
    "# zero_col = np.zeros(df_test.shape[0])\n",
    "# zero_col = pd.DataFrame(zero_col,columns=['id'])\n",
    "# zero_col.iloc[:] = -1\n",
    "# print(zero_col.shape)\n",
    "\n",
    "# df_test[\"TARGET\"] = zero_col\n",
    "# print (df_test.shape)\n",
    "\n",
    "# df_train = pd.concat ([df_train,df_test])\n",
    "# df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75818, 336)\n",
      "(76020, 337)\n"
     ]
    }
   ],
   "source": [
    "# remove constant columns\n",
    "remove = []\n",
    "for col in df_train.columns:\n",
    "    if df_train[col].std() == 0:\n",
    "        remove.append(col)\n",
    "\n",
    "df_train.drop(remove, axis=1, inplace=True)\n",
    "df_test.drop(remove, axis=1, inplace=True)\n",
    "\n",
    "print(df_test.shape)\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39205.170000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49278.030000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67333.770000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>195</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64007.970000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>117310.979016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 337 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0   1     2     23                   0                        0   \n",
       "1   3     2     34                   0                        0   \n",
       "2   4     2     23                   0                        0   \n",
       "3   8     2     37                   0                      195   \n",
       "4  10     2     39                   0                        0   \n",
       "\n",
       "   imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "0                        0                        0                        0   \n",
       "1                        0                        0                        0   \n",
       "2                        0                        0                        0   \n",
       "3                      195                        0                        0   \n",
       "4                        0                        0                        0   \n",
       "\n",
       "   imp_op_var40_efect_ult1  imp_op_var40_efect_ult3   ...    \\\n",
       "0                        0                        0   ...     \n",
       "1                        0                        0   ...     \n",
       "2                        0                        0   ...     \n",
       "3                        0                        0   ...     \n",
       "4                        0                        0   ...     \n",
       "\n",
       "   saldo_medio_var33_hace2  saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "0                        0                        0                       0   \n",
       "1                        0                        0                       0   \n",
       "2                        0                        0                       0   \n",
       "3                        0                        0                       0   \n",
       "4                        0                        0                       0   \n",
       "\n",
       "   saldo_medio_var33_ult3  saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "0                       0                        0                        0   \n",
       "1                       0                        0                        0   \n",
       "2                       0                        0                        0   \n",
       "3                       0                        0                        0   \n",
       "4                       0                        0                        0   \n",
       "\n",
       "   saldo_medio_var44_ult1  saldo_medio_var44_ult3          var38  TARGET  \n",
       "0                       0                       0   39205.170000       0  \n",
       "1                       0                       0   49278.030000       0  \n",
       "2                       0                       0   67333.770000       0  \n",
       "3                       0                       0   64007.970000       0  \n",
       "4                       0                       0  117310.979016       0  \n",
       "\n",
       "[5 rows x 337 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75818, 307)\n",
      "(76020, 308)\n"
     ]
    }
   ],
   "source": [
    "# remove duplicated columns\n",
    "remove = []\n",
    "c = df_train.columns\n",
    "for i in range(len(c)-1):\n",
    "    v = df_train[c[i]].values\n",
    "    for j in range(i+1,len(c)):\n",
    "        if np.array_equal(v,df_train[c[j]].values):\n",
    "            remove.append(c[j])\n",
    "\n",
    "df_train.drop(remove, axis=1, inplace=True)\n",
    "df_test.drop(remove, axis=1, inplace=True)\n",
    "\n",
    "y_train = df_train['TARGET'].values\n",
    "X_train = df_train.drop(['ID','TARGET'], axis=1).values\n",
    "\n",
    "id_test = df_test['ID']\n",
    "X_test = df_test.drop(['ID'], axis=1).values\n",
    "\n",
    "print(df_test.shape)\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76020, 252)\n",
      "(75818, 252)\n"
     ]
    }
   ],
   "source": [
    "## ## removing features with high presence of nulls\n",
    "\n",
    "col_remove = X_train.shape[0]-sum(X_train == 0)<10\n",
    "X_train = X_train[:,~col_remove]\n",
    "X_test = X_test[:,~col_remove]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "##  I would suggest not to change -999999 into anything other  \n",
    "## \n",
    "num_vals = (X_train[:,0]==-999999)\n",
    "print (sum(num_vals))\n",
    "X_train[num_vals,0] = -5\n",
    "\n",
    "num_vals = (X_test[:,0]==-999999)\n",
    "print (sum(num_vals))\n",
    "X_test[num_vals,0] = -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[-0.815198455329, -0.286247315646, -0.18045708...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[-2.17752336546, -2.10034143577, -2.0231595060...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[-0.0533881045344, -0.0533509470036, -0.053202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[-0.21326309134, -0.213174677554, -0.212821022...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[-0.218813460912, -0.21875854228, -0.218703623...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>[-0.0382064799338, 0.000116688850586, 0.007523...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>[-0.0421026657464, -0.0188810472771, -0.014392...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>[-0.0134929222078, 1.94699267562, 2.4135882479...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>[-0.0155382511555, 1.62769980935, 2.0187904677...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>[-0.0331772418678, 0.00429615762251, 0.0115389...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>[-0.215279105992, -0.21518523966, -0.214809774...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>[-0.220749025703, -0.22069044928, -0.220631872...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>[-0.128230600066, -0.100029514529, -0.09692739...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>[-0.11917421676, -0.10338607508, -0.1016493794...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>[-0.196705157219, -0.196662159289, -0.19649016...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>[-0.128145475268, -0.100132713354, -0.09705130...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>[-0.119332748874, -0.10360242703, -0.101872091...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>[-0.196984926278, -0.196942836525, -0.19677447...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>[-0.0117701242411, -0.00854700779294, 0.020461...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>[-0.107658289306, 9.28864843059]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>[-0.0614522189019, 16.2728054067]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>[-4.77736882591, 0.209320242259]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>[-1.40501318416, 0.711737093486]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>[-0.184250097911, 5.42740552836]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>[-0.171579849242, 5.82819022407]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>[-0.269092958578, 3.71618791247]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>[-0.218235932974, 4.58219682879]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>[-0.234797600906, 4.2589872986]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>[-0.211807175043, 4.72127537605]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>[-0.208015904028, 4.80732473161]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>222</td>\n",
       "      <td>[-0.186196092855, -0.149268879435, -0.14049587...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>223</td>\n",
       "      <td>[-0.205294696881, -0.127016982935, -0.03937847...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>224</td>\n",
       "      <td>[-0.0183010162819, -0.0181277346669, -0.017954...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>225</td>\n",
       "      <td>[-1.59890464429, -0.781672124653, -0.390747854...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>226</td>\n",
       "      <td>[-1.00994866991, -0.290631227385, -0.207977075...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>227</td>\n",
       "      <td>[-0.105817248013, -0.105814865352, -0.10581327...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>228</td>\n",
       "      <td>[-0.066023329863, -0.0660168731761, -0.0660136...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>229</td>\n",
       "      <td>[-0.123435769767, -0.123435120447, -0.12343382...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>230</td>\n",
       "      <td>[-0.1239476352, -0.12394256577, -0.12394087596...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>231</td>\n",
       "      <td>[-0.138071240243, -0.13733714565, -0.135868956...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>232</td>\n",
       "      <td>[-0.0774349877003, -0.0758895853004, -0.072794...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>233</td>\n",
       "      <td>[-0.152173371168, -0.144959952262, -0.14276497...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>234</td>\n",
       "      <td>[-0.150861760792, -0.144617058773, -0.14348144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>235</td>\n",
       "      <td>[-0.0589530142813, -0.0367615718007, 0.0522312...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>236</td>\n",
       "      <td>[-0.0345128875447, -0.000310808563718, 0.04787...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>237</td>\n",
       "      <td>[-0.0597836985814, -0.0295548130914, -0.011416...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>238</td>\n",
       "      <td>[-0.0604516081006, -0.021500312719, 0.00187191...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>239</td>\n",
       "      <td>[-0.0059251294038, -0.00592318038677, 0.009667...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>240</td>\n",
       "      <td>[-0.00423383070958, -0.00423034733514, 0.00958...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>241</td>\n",
       "      <td>[-0.00876088643569, 0.0191120792281, 0.0316184...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>242</td>\n",
       "      <td>[-0.00834859710767, 0.023517915986, 0.02619180...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>243</td>\n",
       "      <td>[-0.0174075426481, 0.0529392660976, 0.32438976...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>244</td>\n",
       "      <td>[-0.0119792851754, 0.4679306288, 0.86623216464...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>245</td>\n",
       "      <td>[-0.0155969671359, 0.0770610917838, 0.15918547...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>246</td>\n",
       "      <td>[-0.0163140644186, 0.118465267941, 0.237922435...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>247</td>\n",
       "      <td>[-0.0156500592178, -0.0150241626433, -0.014636...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>248</td>\n",
       "      <td>[-0.0125761564554, -0.00871921807214, 1.555776...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>249</td>\n",
       "      <td>[-0.0188169079843, -0.0184382242893, -0.017873...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>250</td>\n",
       "      <td>[-0.0198468528674, -0.0193525601317, -0.018816...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>251</td>\n",
       "      <td>[-0.613544154031, -0.606334663673, -0.60473352...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               data\n",
       "0      0  [-0.815198455329, -0.286247315646, -0.18045708...\n",
       "1      1  [-2.17752336546, -2.10034143577, -2.0231595060...\n",
       "2      2  [-0.0533881045344, -0.0533509470036, -0.053202...\n",
       "3      3  [-0.21326309134, -0.213174677554, -0.212821022...\n",
       "4      4  [-0.218813460912, -0.21875854228, -0.218703623...\n",
       "5      5  [-0.0382064799338, 0.000116688850586, 0.007523...\n",
       "6      6  [-0.0421026657464, -0.0188810472771, -0.014392...\n",
       "7      7  [-0.0134929222078, 1.94699267562, 2.4135882479...\n",
       "8      8  [-0.0155382511555, 1.62769980935, 2.0187904677...\n",
       "9      9  [-0.0331772418678, 0.00429615762251, 0.0115389...\n",
       "10    10  [-0.215279105992, -0.21518523966, -0.214809774...\n",
       "11    11  [-0.220749025703, -0.22069044928, -0.220631872...\n",
       "12    12  [-0.128230600066, -0.100029514529, -0.09692739...\n",
       "13    13  [-0.11917421676, -0.10338607508, -0.1016493794...\n",
       "14    14  [-0.196705157219, -0.196662159289, -0.19649016...\n",
       "15    15  [-0.128145475268, -0.100132713354, -0.09705130...\n",
       "16    16  [-0.119332748874, -0.10360242703, -0.101872091...\n",
       "17    17  [-0.196984926278, -0.196942836525, -0.19677447...\n",
       "18    18  [-0.0117701242411, -0.00854700779294, 0.020461...\n",
       "19    19                   [-0.107658289306, 9.28864843059]\n",
       "20    20                  [-0.0614522189019, 16.2728054067]\n",
       "21    21                   [-4.77736882591, 0.209320242259]\n",
       "22    22                   [-1.40501318416, 0.711737093486]\n",
       "23    23                   [-0.184250097911, 5.42740552836]\n",
       "24    24                   [-0.171579849242, 5.82819022407]\n",
       "25    25                   [-0.269092958578, 3.71618791247]\n",
       "26    26                   [-0.218235932974, 4.58219682879]\n",
       "27    27                    [-0.234797600906, 4.2589872986]\n",
       "28    28                   [-0.211807175043, 4.72127537605]\n",
       "29    29                   [-0.208015904028, 4.80732473161]\n",
       "..   ...                                                ...\n",
       "222  222  [-0.186196092855, -0.149268879435, -0.14049587...\n",
       "223  223  [-0.205294696881, -0.127016982935, -0.03937847...\n",
       "224  224  [-0.0183010162819, -0.0181277346669, -0.017954...\n",
       "225  225  [-1.59890464429, -0.781672124653, -0.390747854...\n",
       "226  226  [-1.00994866991, -0.290631227385, -0.207977075...\n",
       "227  227  [-0.105817248013, -0.105814865352, -0.10581327...\n",
       "228  228  [-0.066023329863, -0.0660168731761, -0.0660136...\n",
       "229  229  [-0.123435769767, -0.123435120447, -0.12343382...\n",
       "230  230  [-0.1239476352, -0.12394256577, -0.12394087596...\n",
       "231  231  [-0.138071240243, -0.13733714565, -0.135868956...\n",
       "232  232  [-0.0774349877003, -0.0758895853004, -0.072794...\n",
       "233  233  [-0.152173371168, -0.144959952262, -0.14276497...\n",
       "234  234  [-0.150861760792, -0.144617058773, -0.14348144...\n",
       "235  235  [-0.0589530142813, -0.0367615718007, 0.0522312...\n",
       "236  236  [-0.0345128875447, -0.000310808563718, 0.04787...\n",
       "237  237  [-0.0597836985814, -0.0295548130914, -0.011416...\n",
       "238  238  [-0.0604516081006, -0.021500312719, 0.00187191...\n",
       "239  239  [-0.0059251294038, -0.00592318038677, 0.009667...\n",
       "240  240  [-0.00423383070958, -0.00423034733514, 0.00958...\n",
       "241  241  [-0.00876088643569, 0.0191120792281, 0.0316184...\n",
       "242  242  [-0.00834859710767, 0.023517915986, 0.02619180...\n",
       "243  243  [-0.0174075426481, 0.0529392660976, 0.32438976...\n",
       "244  244  [-0.0119792851754, 0.4679306288, 0.86623216464...\n",
       "245  245  [-0.0155969671359, 0.0770610917838, 0.15918547...\n",
       "246  246  [-0.0163140644186, 0.118465267941, 0.237922435...\n",
       "247  247  [-0.0156500592178, -0.0150241626433, -0.014636...\n",
       "248  248  [-0.0125761564554, -0.00871921807214, 1.555776...\n",
       "249  249  [-0.0188169079843, -0.0184382242893, -0.017873...\n",
       "250  250  [-0.0198468528674, -0.0193525601317, -0.018816...\n",
       "251  251  [-0.613544154031, -0.606334663673, -0.60473352...\n",
       "\n",
       "[252 rows x 2 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = map(lambda x: np.unique(X_train[:,x]), range(X_train.shape[1]))\n",
    "pd.DataFrame({'data': tt,'id': range(X_train.shape[1])},columns=['id','data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -1.00000000e+00  -5.00000000e-01   0.00000000e+00   8.00000000e+00\n",
      "   1.00000000e+10]\n",
      "[ -1.00000000e+00  -5.00000000e-01  -3.33333333e-01   0.00000000e+00\n",
      "   6.00000000e+00   1.00000000e+10]\n"
     ]
    }
   ],
   "source": [
    "print (np.unique(X_train[:,150]))\n",
    "print (np.unique(X_test[:,150]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "st_scale = StandardScaler(True, True, True)\n",
    "X_train = st_scale.fit_transform(X_train)\n",
    "X_test = st_scale.transform (X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "343"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(X_train[:,46] == -14.853708394243661)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -2.35115248e-02  -2.35115227e-02  -2.35115205e-02  -2.35114865e-02\n",
      "   4.25323406e+01]\n",
      "[ -1.00000000e+00  -5.00000000e-01  -3.33333333e-01   0.00000000e+00\n",
      "   6.00000000e+00   1.00000000e+10]\n"
     ]
    }
   ],
   "source": [
    "print (np.unique(X_train[:,150]))\n",
    "print (np.unique(X_test[:,150]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEGCAYAAACAd+UpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njCFPRJTBGPJERBmMIU9ElMH+Dxq+7qZulwTUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbe58cfce10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.plot(X_test.mean(axis=0), color =\"b\")\n",
    "plt.plot(X_train.mean(axis=0), color =\"r\")\n",
    "plt.show()\n",
    "#X_test.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plt.plot(X_test.mean(axis=0), color =\"b\")\n",
    "plt.plot(X_train.mean(axis=0), color =\"r\")\n",
    "plt.show()\n",
    "#X_test.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTrees done\n",
      "[251   1 220 222 218 216 215 219 184 217 221 186 181 129 182 135 117 137\n",
      "  47 183 194 187 185  22   2  16   0  17  11  14]\n"
     ]
    }
   ],
   "source": [
    "## Feature selection\n",
    "\n",
    "clf = ExtraTreesClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "feature_selected = clf.feature_importances_\n",
    "\n",
    "print (\"ExtraTrees done\")\n",
    "\n",
    "feature_selected = np.argsort(-feature_selected)\n",
    "print (feature_selected[0:30])\n",
    "\n",
    "##   [305   1 268 270 266 264 263 221 265 267 223 150 143 269 219 218 128 224\n",
    "##    152 220  22 233 222   2  11 189  71  13  14   4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75818, 268)\n",
      "(76020, 268)\n"
     ]
    }
   ],
   "source": [
    "## Converting cities to numbers\n",
    "\n",
    "for j in np.unique(X_train[:,0]):\n",
    "    if sum(X_train[:,0]==j)>60:\n",
    "        new_col = np.zeros(X_train.shape[0])\n",
    "        new_col[(X_train[:,0]==j)] = 1\n",
    "        X_train = np.column_stack((X_train, new_col))  \n",
    "\n",
    "        new_col = np.zeros(X_test.shape[0])\n",
    "        new_col[(X_test[:,0]==j)] = 1\n",
    "        X_test = np.column_stack((X_test, new_col))  \n",
    "\n",
    "print (X_test.shape)\n",
    "print (X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count columns:  44\n",
      "76.02\n",
      "(75818, 269)\n",
      "(76020, 269)\n"
     ]
    }
   ],
   "source": [
    "def count_zeros(a):\n",
    "    return sum(a==0)\n",
    "\n",
    "# first select columns which are biased to zeroes:\n",
    "\n",
    "tt = np.apply_along_axis(count_zeros, 0, X_train)\n",
    "sel_cols = (tt > X_train.shape[0]*0.999)\n",
    "print \"count columns: \", sum(sel_cols)\n",
    "print (X_train.shape[0]-X_train.shape[0]*0.999)\n",
    "\n",
    "# calculate number of zeroes in this columns\n",
    "\n",
    "tt = np.apply_along_axis(count_zeros, 1, X_train[:,sel_cols])\n",
    "X_train = np.column_stack((X_train, tt)) \n",
    "\n",
    "tt = np.apply_along_axis(count_zeros, 1, X_test[:,sel_cols])\n",
    "X_test = np.column_stack((X_test, tt)) \n",
    "\n",
    "print (X_test.shape)\n",
    "print (X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75818, 533)\n",
      "(76020, 533)\n"
     ]
    }
   ],
   "source": [
    "#  https://www.kaggle.com/c/homesite-quote-conversion/forums/t/18837/what-is-your-best-single-model-score-and-how-did-you-achieve-it\n",
    "#\n",
    "#  Adding log features\n",
    "\n",
    "feat = feature_selected[0:100]\n",
    "\n",
    "c = X_train.shape[1]\n",
    "\n",
    "k = 0\n",
    "\n",
    "for i in feat:\n",
    "    k = k+1\n",
    "    if sum(X_train[:,i]<0)==0:\n",
    "        new_col = np.log(X_train[:,i]+1)\n",
    "        X_train = np.column_stack((X_train, new_col))\n",
    "\n",
    "        new_col = np.sqrt(X_train[:,i])\n",
    "        X_train = np.column_stack((X_train, new_col))\n",
    "\n",
    "        new_col = 1/(0.001 + X_train[:,i])\n",
    "        X_train = np.column_stack((X_train, new_col))        \n",
    "        \n",
    "        \n",
    "        new_col = np.log(X_test[:,i]+1)\n",
    "        X_test = np.column_stack((X_test, new_col))\n",
    "\n",
    "        new_col = np.sqrt(X_test[:,i])\n",
    "        X_test = np.column_stack((X_test, new_col))\n",
    "\n",
    "        new_col = 1/(0.001 + X_test[:,i])\n",
    "        X_test = np.column_stack((X_test, new_col))      \n",
    "        \n",
    "        \n",
    "            # classifier\n",
    "#     clf = xgb.XGBClassifier(missing=np.nan, max_depth=3, n_estimators=550, learning_rate=0.03, nthread=8, subsample=0.95, colsample_bytree=0.85, seed=4242)\n",
    "\n",
    "#     X_fit, X_eval, y_fit, y_eval = train_test_split(X_train, y_train, test_size=0.5, random_state = 84)\n",
    "\n",
    "#     # fitting\n",
    "#     #clf.fit(X_train, y_train, early_stopping_rounds=20, eval_metric=\"auc\", eval_set=[(X_eval, y_eval)])\n",
    "\n",
    "#     clf.fit(X_fit, y_fit, early_stopping_rounds=20, eval_metric=\"auc\", eval_set=[(X_eval, y_eval)])\n",
    "\n",
    "#     print(k, 'Overall AUC:', roc_auc_score(y_train, clf.predict_proba(X_train)[:,1]), roc_auc_score(y_eval, clf.predict_proba(X_eval)[:,1]))\n",
    "\n",
    "    \n",
    "print(X_test.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_train.tofile(\"Data/proc_train.csv\", sep=\",\",format=\"%.2f\")\n",
    "#X_test.tofile(\"Data/proc_test.csv\", sep=\",\",format=\"%.2f\")\n",
    "\n",
    "np.savetxt(\"Data/proc_train.csv\", X_train, delimiter=\",\",  fmt='%.3e')\n",
    "np.savetxt(\"Data/proc_test.csv\", X_test, delimiter=\",\",  fmt='%.3e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# length of dataset\n",
    "len_train = len(X_train)\n",
    "len_test  = len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tt = np.apply_along_axis(count_zeros, 0, X_train)\n",
    "\n",
    "# for j in range(X_train.shape[1]):\n",
    "#     sum_zero = sum(X_train[:,j] != 0)\n",
    "#     val_zero = (sum(X_train[:,j] == 0)*1.0/X_train.shape[0])\n",
    "#     val_zero = np.round(val_zero,4)\n",
    "    \n",
    "#     val_one  = (sum(y_train[(X_train[:,j] == 0)] == 1)*1.0/max(1,sum(X_train[:,j] == 0)))\n",
    "#     val_one = np.round(val_one,4)\n",
    "    \n",
    "#     perc_one  = (sum(y_train[(X_train[:,j] == 0)] == 1)*1.0/sum(y_train==1))\n",
    "#     perc_one = np.round(perc_one,4)\n",
    "#     print j,sum_zero, val_zero, val_one, perc_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Overall AUC:', 0.8800392952200512, 0.87641951466519619)\n"
     ]
    }
   ],
   "source": [
    "# classifier\n",
    "clf = xgb.XGBClassifier(missing=np.nan, max_depth=5, n_estimators=310, learning_rate=0.03, nthread=8, subsample=0.95, colsample_bytree=0.85, seed=4242)\n",
    "\n",
    "X_fit, X_eval, y_fit, y_eval = train_test_split(X_train, y_train, test_size=0.3, random_state = 84)\n",
    "\n",
    "# fitting\n",
    "#clf.fit(X_train, y_train, early_stopping_rounds=20, eval_metric=\"auc\", eval_set=[(X_eval, y_eval)])\n",
    "\n",
    "clf.fit(X_train, y_train, early_stopping_rounds=20, eval_metric=\"auc\", eval_set=[(X_eval, y_eval)])\n",
    "\n",
    "print('Overall AUC:', roc_auc_score(y_train, clf.predict_proba(X_train)[:,1]), roc_auc_score(y_eval, clf.predict_proba(X_eval)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed!\n"
     ]
    }
   ],
   "source": [
    "# predicting\n",
    "y_pred= clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "submission = pd.DataFrame({\"ID\":id_test, \"TARGET\":y_pred})\n",
    "submission.to_csv(\"predictions/submission_xgb.csv\", index=False)\n",
    "\n",
    "print('Completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.82925183744912734, 0.81684513695019678, 0.82676223764149526)\n",
      "(0.8387333682605963, 0.81403982661370033, 0.83378117410530594)\n",
      "(0.85722421034670082, 0.842733223637958, 0.85432520938338907)\n",
      "(0.85429906580611092, 0.8525390044123603, 0.85394502559547192)\n",
      "(0.85567309707810935, 0.83600849244319786, 0.8517707345870571)\n",
      "\n",
      "\n",
      "('results: ', 0.81403982661370033, 0.8525390044123603, 0.83243313681148268)\n"
     ]
    }
   ],
   "source": [
    "## Learning with cross_validation\n",
    "\n",
    "skf = StratifiedKFold (y_train,n_folds=5, random_state = 48)\n",
    "\n",
    "rc_eval_dt = []\n",
    "for fit_index, test_index in skf:\n",
    "        # print(\"TRAIN:\", fit_index, \"TEST:\", test_index)\n",
    "        X_fit, X_eval = X_train[fit_index], X_train[test_index]\n",
    "        y_fit, y_eval = y_train[fit_index], y_train[test_index]\n",
    "        \n",
    "        clf.fit(X_fit, y_fit, early_stopping_rounds=20, eval_metric=\"auc\", eval_set=[(X_eval, y_eval)])\n",
    "        \n",
    "        rc_fit  = roc_auc_score(y_fit, clf.predict_proba(X_fit)[:,1])\n",
    "        rc_eval = roc_auc_score(y_eval, clf.predict_proba(X_eval)[:,1])\n",
    "        rc_train  = roc_auc_score(y_train, clf.predict_proba(X_train)[:,1])\n",
    "        \n",
    "        rc_eval_dt.append(rc_eval)\n",
    "        print (rc_fit,rc_eval,rc_train)\n",
    "\n",
    "rc_eval_dt = np.array(rc_eval_dt)\n",
    "print (\"\\n\")\n",
    "print (\"results: \", rc_eval_dt.min(),rc_eval_dt.max(),rc_eval_dt.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.82581993002108967, 0.81269680625857832, 0.82319398494389151)\n",
      "(0.86104645919428469, 0.82507184046967996, 0.85385450564596777)\n",
      "(0.83039059245682523, 0.82318304141652632, 0.82894476104773207)\n",
      "(0.83222389229268878, 0.84593146016740117, 0.83496609071694428)\n",
      "(0.85769822822451824, 0.83669988224438052, 0.85352193817454669)\n",
      "('results: ', 50, ' -- ', 0.81269680625857832, 0.84593146016740117, 0.82871660611131337)\n",
      "(0.82733447416914574, 0.81358111915746611, 0.82458376213440876)\n",
      "(0.85998455910990956, 0.82430600092867645, 0.85286227631919442)\n",
      "(0.82385337019831295, 0.81647925396830456, 0.82237803274614718)\n",
      "(0.85563373163944945, 0.85193541285457441, 0.85489688293370025)\n",
      "(0.85948815896567154, 0.83640634781869516, 0.85489201316076291)\n",
      "('results: ', 75, ' -- ', 0.81358111915746611, 0.85193541285457441, 0.82854162694554334)\n",
      "(0.86151882117940148, 0.83478608705306312, 0.85617356255048715)\n",
      "(0.86176085492922494, 0.82525998730975725, 0.85446189541780371)\n",
      "(0.82026233281146843, 0.81221392099839773, 0.81865052094322011)\n",
      "(0.82098285638524904, 0.83660667139026157, 0.82411022851023608)\n",
      "(0.85971514416058237, 0.83582759729538103, 0.85495780176692027)\n",
      "('results: ', 100, ' -- ', 0.81221392099839773, 0.83660667139026157, 0.82893885280937218)\n",
      "(0.86249645934869779, 0.83526458746587129, 0.85704945461821491)\n",
      "(0.83746034196582664, 0.81423240980611311, 0.83281573877465198)\n",
      "(0.85820952739989886, 0.8417945295802105, 0.85491325438633814)\n",
      "(0.85465666573276433, 0.85242966967577438, 0.8542206242364998)\n",
      "(0.85992441152954635, 0.8366346460414672, 0.855297916361898)\n",
      "('results: ', 125, ' -- ', 0.81423240980611311, 0.85242966967577438, 0.83607116851388741)\n",
      "(0.85811170524839842, 0.83441286469375631, 0.85337054037167892)\n",
      "(0.86016423342108128, 0.82571357589791194, 0.85327377782404756)\n",
      "(0.85942894717779539, 0.84293867494599795, 0.85612755583168487)\n",
      "(0.85602150023681856, 0.85225857420210716, 0.85527241550791422)\n",
      "(0.83205264605523743, 0.82190949613494013, 0.83003365957913067)\n",
      "('results: ', 150, ' -- ', 0.82190949613494013, 0.85225857420210716, 0.83544663717494261)\n",
      "(0.85958513066349973, 0.83470242199811939, 0.85461147189371967)\n",
      "(0.85895876822521933, 0.82572762434697466, 0.85232225287798791)\n",
      "(0.86069415287894524, 0.84301756779324366, 0.85715381209923514)\n",
      "(0.85680769942316415, 0.85252236775624612, 0.85596032614428874)\n",
      "(0.86222500116826684, 0.83654741754656725, 0.85712416544977743)\n",
      "('results: ', 175, ' -- ', 0.82572762434697466, 0.85252236775624612, 0.83850347988823037)\n",
      "(0.85986026718146458, 0.83437049184132062, 0.85476295848627615)\n",
      "(0.83856073504767814, 0.81479343774762536, 0.83379862924748016)\n",
      "(0.83076830408712554, 0.82384222613659164, 0.82937058956571985)\n",
      "(0.85619306654740035, 0.8529702470497853, 0.85555047066366829)\n",
      "(0.86009408229592299, 0.83671657587534454, 0.85543926499330925)\n",
      "('results: ', 200, ' -- ', 0.81479343774762536, 0.8529702470497853, 0.83253859573013356)\n",
      "(0.82766460881586501, 0.81397248506029907, 0.82492075998364001)\n",
      "(0.83942468385184199, 0.81503311452636928, 0.83453955188144535)\n",
      "(0.85700438525896072, 0.84263789241086073, 0.85412655725275699)\n",
      "(0.85420793031680775, 0.85252031666165662, 0.8538753871594702)\n",
      "(0.86115310826217573, 0.83736540546379679, 0.85642283846374423)\n",
      "('results: ', 225, ' -- ', 0.81397248506029907, 0.85252031666165662, 0.83230584282459641)\n",
      "(0.8279328394360479, 0.81400433579501597, 0.82514992844734936)\n",
      "(0.86281613019048309, 0.82582937606913254, 0.85541857471913685)\n",
      "(0.86072301412763819, 0.84295408948212169, 0.8571650474098691)\n",
      "(0.85528581570317197, 0.85293782836030252, 0.85481446561247287)\n",
      "(0.85946831443159233, 0.83629598753481449, 0.8548656494531357)\n",
      "('results: ', 250, ' -- ', 0.81400433579501597, 0.85293782836030252, 0.83440432344827742)\n",
      "(0.82415459821002823, 0.81182153669329771, 0.82168357216272236)\n",
      "(0.83771904806856379, 0.81423946246880052, 0.83301509894613646)\n",
      "(0.85846850658550222, 0.8424241934727914, 0.85525023629895869)\n",
      "(0.85866927319998521, 0.85202771211109829, 0.85734654264061516)\n",
      "(0.86106908550910144, 0.83707580230274115, 0.85630243509227866)\n",
      "('results: ', 275, ' -- ', 0.81182153669329771, 0.85202771211109829, 0.83151774140974588)\n",
      "(0.82586485215678973, 0.81282455045531765, 0.82325335109588504)\n",
      "(0.8568020609732212, 0.82518263552544502, 0.85047956403770997)\n",
      "(0.82693557153170827, 0.82015502359163461, 0.82557512405422129)\n",
      "(0.83228541390470223, 0.84505951706749993, 0.83483908048196098)\n",
      "(0.86062190778237901, 0.83667532608415729, 0.85585730961523665)\n",
      "('results: ', 300, ' -- ', 0.81282455045531765, 0.84505951706749993, 0.82797941054481095)\n",
      "(0.86044677394382929, 0.83361949701774751, 0.85508320695752715)\n",
      "(0.85734219041586057, 0.82506256963082492, 0.85088725213925775)\n",
      "(0.85943867077156733, 0.84300920640280008, 0.85614117708062576)\n",
      "(0.85457908711871389, 0.85293885390759727, 0.85425313719924789)\n",
      "(0.86276314012225508, 0.83721362446418013, 0.85768225417768695)\n",
      "('results: ', 325, ' -- ', 0.82506256963082492, 0.85293885390759727, 0.83836875028462998)\n"
     ]
    }
   ],
   "source": [
    "d_var = [50,75,100,125,150,175,200,225,250,275,300,325]\n",
    "\n",
    "for d in d_var:\n",
    "    skf = StratifiedKFold (y_train,n_folds=5, random_state = 48)\n",
    "\n",
    "    rc_eval_dt = []\n",
    "    for fit_index, test_index in skf:\n",
    "\n",
    "            # print(\"TRAIN:\", fit_index, \"TEST:\", test_index)\n",
    "            X_fit, X_eval = X_train[fit_index][:,feature_selected[0:d]], X_train[test_index][:,feature_selected[0:d]]\n",
    "            y_fit, y_eval = y_train[fit_index], y_train[test_index]\n",
    "            \n",
    "            clf = xgb.XGBClassifier(missing=np.nan, max_depth=3, n_estimators=550, learning_rate=0.03, nthread=8, subsample=0.95, colsample_bytree=0.85, seed=4242)\n",
    "            clf.fit(X_fit, y_fit, early_stopping_rounds=20, eval_metric=\"auc\", eval_set=[(X_eval, y_eval)])    \n",
    "            \n",
    "            rc_fit  = roc_auc_score(y_fit, clf.predict_proba(X_fit)[:,1])\n",
    "            rc_eval = roc_auc_score(y_eval, clf.predict_proba(X_eval)[:,1])\n",
    "            rc_train  = roc_auc_score(y_train, clf.predict_proba(X_train[:,feature_selected[0:d]])[:,1])\n",
    "            rc_eval_dt.append(rc_eval)\n",
    "            \n",
    "            print (rc_fit,rc_eval,rc_train)\n",
    "\n",
    "    rc_eval_dt = np.array(rc_eval_dt)\n",
    "\n",
    "    #print (\"\\n\")\n",
    "    print (\"results: \",d,\" -- \",rc_eval_dt.min(),rc_eval_dt.max(),rc_eval_dt.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0389634306761\n",
      "(38010, 1481)\n",
      "0.0401736385162\n",
      "(38010, 1527)\n"
     ]
    }
   ],
   "source": [
    "print (sum(y_fit==1)*1.0/len(y_fit))\n",
    "print (len(y_fit), sum(y_fit==1))\n",
    "print (sum(y_eval==1)*1.0/len(y_eval))\n",
    "print (len(y_eval), sum(y_eval==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  39205.17      ,   49278.03      ,   67333.77      , ...,\n",
       "         74028.15      ,   84278.16      ,  117310.97901649])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0., -1.,  0., ...,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-cb2f700abd97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdata_plt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_plt\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#data_plt = data_plt[data_plt<25]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mplt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_plt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_plt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hist' is not defined"
     ]
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_plt = X_train[:,28]\n",
    "data_plt = data_plt[data_plt>=0]            \n",
    "data_plt = np.log(data_plt+1)\n",
    "#data_plt = data_plt[data_plt<25]\n",
    "plt = hist(data_plt,10)\n",
    "\n",
    "for j in unique(data_plt):\n",
    "    print round(j,2), sum(data_plt==j), sum(y_train[data_plt==j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
